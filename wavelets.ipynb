{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64e97b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 14:11:06.834000: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-22 14:11:06.837322: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-22 14:11:06.849190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-22 14:11:06.873202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-22 14:11:06.873234: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-22 14:11:06.887690: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-22 14:11:07.872051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pp\n",
    "from que_onda import *\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "np.set_printoptions(floatmode='unique')\n",
    "dtype = tf.float32\n",
    "n_levels = 10\n",
    "wavelet_name = 'sym6'\n",
    "\n",
    "wavelet = wavelets.by_name(wavelet_name, dtype)\n",
    "filters = wavelets.dwt_filters(wavelet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e8bfcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexanderRoss_VelvetCurtain_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "CelestialShore_DieForUs_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "ClaraBerryAndWooldog_TheBadGuys_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "ClaraBerryAndWooldog_WaltzForMyVictims_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "Debussy_LenfantProdigue_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "EthanHein_BluesForNofi_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "Allegria_MendelssohnMovement1_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "BarefootSisters_RedJetta_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "CatMartino_IPromise_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "Cayetana_MissThing_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "DeclareAString_MendelssohnPianoTrio1Movement1_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n",
      "DeclareAString_MendelssohnPianoTrio1Movement2_MIX: 44100Hz\n",
      "num channels: 2\n",
      "samplerate: 44100\n"
     ]
    }
   ],
   "source": [
    "# files = os.walk('data/mp3')\n",
    "files = [\n",
    "         ('data/mp3/MedleyDB_V1', [], [\n",
    "                                   'AlexanderRoss_VelvetCurtain_MIX.mp3',\n",
    "                                   'CelestialShore_DieForUs_MIX.mp3',\n",
    "                                   'ClaraBerryAndWooldog_TheBadGuys_MIX.mp3',\n",
    "                                   'ClaraBerryAndWooldog_WaltzForMyVictims_MIX.mp3',\n",
    "                                   'Debussy_LenfantProdigue_MIX.mp3',\n",
    "                                   'EthanHein_BluesForNofi_MIX.mp3'\n",
    "                                   ]),\n",
    "         ('data/mp3/MedleyDB_V2', [], [\n",
    "                                   'Allegria_MendelssohnMovement1_MIX.mp3',\n",
    "                                   'BarefootSisters_RedJetta_MIX.mp3',\n",
    "                                   'CatMartino_IPromise_MIX.mp3',\n",
    "                                   'Cayetana_MissThing_MIX.mp3',\n",
    "                                   'DeclareAString_MendelssohnPianoTrio1Movement1_MIX.mp3',\n",
    "                                   'DeclareAString_MendelssohnPianoTrio1Movement2_MIX.mp3'\n",
    "                                  ])]\n",
    "\n",
    "all_as = []\n",
    "all_bs = []\n",
    "all_cs = []\n",
    "beat_lengths = []\n",
    "min_beat_length = 9\n",
    "max_beat_length = 63\n",
    "max_lags = 188\n",
    "\n",
    "# Logarithmic Decay with Shift: y = a * log(x + c) + b\n",
    "def logarithmic_decay_shifted(x, a, b, c):\n",
    "    return a * np.log(x + c) + b\n",
    "\n",
    "vorbis_chunk_size = 128 * 1024\n",
    "\n",
    "def write_channels_vorbis(filename, channels, samplerate):\n",
    "    samples = tf.transpose(channels)\n",
    "    np_samples = samples.numpy()\n",
    "    with sf.SoundFile(filename, mode='w', channels=channels.shape[0], format='OGG', samplerate=samplerate, subtype='VORBIS') as file:\n",
    "        for i in range(0, np_samples.shape[0], vorbis_chunk_size):\n",
    "            chunk = np_samples[i:i+vorbis_chunk_size]\n",
    "            file.write(chunk)\n",
    "\n",
    "for dirpath, dirnames, filenames in files:\n",
    "    for filename in filenames:\n",
    "        basename, _ = os.path.splitext(filename)\n",
    "        in_channels, samplerate = io.read_channels(os.path.join(dirpath, filename))\n",
    "        # in_levels = wavelets.wavedec_same(filters, n_levels, in_channels)\n",
    "        # in_frames = framing.levels_to_frames(in_levels)\n",
    "        # frame_level_energies = analysis.energy_by_frame_and_level(in_frames)\n",
    "        # frame_power = analysis.power_by_frame(frame_level_energies)\n",
    "\n",
    "        # x_data = np.arange(0, max_lags + 1)\n",
    "        # y_data = tfp.stats.auto_correlation(frame_power, max_lags=max_lags).numpy()\n",
    "\n",
    "        # short_x_data = x_data[min_beat_length:max_beat_length]\n",
    "        # short_y_data = y_data[min_beat_length:max_beat_length]\n",
    "\n",
    "        # # peaks, peak_properties = find_peaks(y_data, prominence=0.006, width=2)\n",
    "        # # plt.plot(x_data, y_data)\n",
    "        # # plt.plot(peaks + min_beat_length, y_data[peaks], 'x')\n",
    "        # # plt.savefig(f'temp/{basename}-lin.png')\n",
    "        # # plt.close()\n",
    "\n",
    "        # # shifted logarithmic decay model (Gemini)\n",
    "        # try:\n",
    "        #     popt_shifted, pcov_shifted = curve_fit(logarithmic_decay_shifted, x_data, y_data, p0=(-0.08439892383834803, 0.7862034695405674, 0.07126941591678249))\n",
    "        # except Exception as e:\n",
    "        #     print(f'!!! could not fit {basename}: {e}')\n",
    "        #     continue\n",
    "        # a_opt_shifted, b_opt_shifted, c_opt_shifted = popt_shifted\n",
    "        # all_as.append(a_opt_shifted)\n",
    "        # all_bs.append(b_opt_shifted)\n",
    "        # all_cs.append(c_opt_shifted)\n",
    "        # print(f'y = {a_opt_shifted} * e^(x+{c_opt_shifted}) + {b_opt_shifted}')\n",
    "\n",
    "        # # Generate points for the fitted curves\n",
    "        # y_fit_shifted = logarithmic_decay_shifted(short_x_data, *popt_shifted)\n",
    "        # diff = short_y_data - y_fit_shifted\n",
    "\n",
    "        # raw_peaks, peak_properties = find_peaks(diff, prominence=0.008, width=2)\n",
    "        # peaks = raw_peaks + min_beat_length\n",
    "        # beat_lengths.extend(peaks)\n",
    "        # pp(peak_properties)\n",
    "\n",
    "        # # Plot the data and the fits\n",
    "        # plt.plot(short_x_data, y_fit_shifted)\n",
    "        # plt.plot(x_data, y_data)\n",
    "        # plt.plot(peaks, y_data[peaks], 'x')\n",
    "        # plt.savefig(f'temp/{basename}-log.png')\n",
    "        # plt.close()\n",
    "        # print()\n",
    "\n",
    "        # # beat_length = beats.find_length(frame_power)\n",
    "\n",
    "        # # x = np.arange(1, 202)\n",
    "        # # autocorrelation = tfp.stats.auto_correlation(frame_power, max_lags=200)\n",
    "        # # np_autocorrelation = autocorrelation.numpy()\n",
    "        # # beat_lengths.extend(peaks)\n",
    "\n",
    "        # # https://www.geeksforgeeks.org/how-to-do-exponential-and-logarithmic-curve-fitting-in-python/\n",
    "        # # logarithmic\n",
    "        # # log_x = np.log(x)\n",
    "        # # a, b = np.polyfit(log_x, np_autocorrelation, 1)\n",
    "        # # est = (a * log_x) + b\n",
    "        # # flattened = np_autocorrelation - est\n",
    "\n",
    "        # # for beat_length in peaks:\n",
    "        # #     n_frames = frame_power.shape[0]\n",
    "        # #     n_beats = n_frames // beat_length\n",
    "        # #     cut = frame_power[:n_beats * beat_length]\n",
    "        # #     intrabeat_power = tf.reshape(cut, [-1, beat_length])\n",
    "        # #     means = tf.reduce_mean(intrabeat_power, axis=0)\n",
    "        # #     plt.plot(means)\n",
    "        # #     plt.savefig(f'temp/{basename}-{beat_length}.png')\n",
    "        # #     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.median(all_as), np.median(all_bs), np.median(all_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb79ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(beat_lengths, bins=range(min(beat_lengths) - 1, max(beat_lengths) + 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d746147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, song, beat_length = 1, 'MusicDelta_Rock', 95                        # 49.5% (or 47, 20.5%)\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Zeppelin', 94                      # 25.7% (or 23)\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_80sRock', 94                     # 61.5% (or 47, 64.6%)\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Reggae', 94                      # 52.8% (or 47, 60.3%)\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Hendrix',  94                    # 67.6%\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_InTheHalloftheMountainKing', 94  # 65.9%\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Country2', 94                    # 71.7%\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Shadows', 94                     # 26.0%\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Vivaldi', 93                       # 27.2% (or 47, 35.8%)\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Rockabilly', 94                  # 71.9%\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Beethoven', 93                   # 24.4%\n",
    "# dataset, song, beat_length = 1, 'MusicDelta_Beatles', 94                     # 44.3%\n",
    "# dataset, song, beat_length = 2, 'Katzn_CharlieKnox', 42\n",
    "# dataset, song, beat_length = 1, 'Creepoid_OldTree', 19\n",
    "# dataset, song, beat_length = 1, 'TheSoSoGlos_Emergency', 29\n",
    "# dataset, song, beat_length = 1, 'BigTroubles_Phantom', 21\n",
    "# dataset, song, beat_length = 1, 'CelestialShore_DieForUs', 30\n",
    "# dataset, song, beat_length = 1, 'TheDistricts_Vermont', 28\n",
    "\n",
    "in_channels, samplerate = io.read_channels(f'data/MedleyDB_V{dataset}/{song}_MIX.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca40170",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'sym6'\n",
    "n_levels = 10\n",
    "\n",
    "wavelet = wavelets.by_name(name, dtype)\n",
    "filters = wavelets.dwt_filters(wavelet)\n",
    "inverse_filters = wavelets.idwt_filters(wavelet)\n",
    "in_levels = wavelets.wavedec_same(filters, n_levels, in_channels)\n",
    "in_frames = framing.levels_to_frames(in_levels)\n",
    "n_frames = in_frames[0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_level_energies = analysis.energy_by_frame_and_level(in_frames)\n",
    "frame_energies = analysis.energy_by_frame(frame_level_energies)\n",
    "autocorrelation = tfp.stats.auto_correlation(frame_energies, max_lags=100)\n",
    "np_autocorrelation = autocorrelation.numpy()\n",
    "\n",
    "peaks, peak_properties = find_peaks(np_autocorrelation, height=0, prominence=0.05, width=1)\n",
    "print(peaks)\n",
    "first_peak = peaks[0]\n",
    "print(f'first peak: {first_peak}')\n",
    "print(f'properties: {peak_properties}')\n",
    "print(f'At first peak: {np_autocorrelation[first_peak]}')\n",
    "plt.plot(np_autocorrelation)\n",
    "plt.plot(peaks, np_autocorrelation[peaks], 'x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e492f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = beats.find_offset(frame_energies, beat_length)\n",
    "in_beats = beats.frames_to_beats(beat_length, in_frames, offset)\n",
    "beat_level_energies = beats.energy_by_beat_and_level(in_beats)\n",
    "beat_level_power = tf.sqrt(beat_level_energies)\n",
    "distances = analysis.manhattan_distance_matrix(beat_level_power)\n",
    "route = defrag.defrag(distances, time_limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reduce_max(beat_level_power, axis=0))\n",
    "\n",
    "remixed = tf.gather(beat_level_power, route)\n",
    "for l in tf.transpose(remixed):\n",
    "    plt.plot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524316e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_beats = beats.remix(in_beats, route)\n",
    "out_frames = beats.beats_to_frames(out_beats)\n",
    "out_levels = framing.frames_to_levels(out_frames)\n",
    "out_channels = wavelets.waverec(inverse_filters, out_levels)\n",
    "io.write_channels(f'temp/{song}-{name}-{beat_length}-sqrt.mp3', out_channels, samplerate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e1813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "sf.available_formats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
